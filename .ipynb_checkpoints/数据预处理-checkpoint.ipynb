{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理未标签数据 对每个样本都检测时候有分类标签 如果这个样本只有一个标签 则认为这个样本是属于这个标签的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                            content\n",
      "0          0  区块链正在以前所未有的速度发展。根据IDC数据，2018年中国区块链市场支出规模达1.6亿美...\n",
      "1          1  明天就是儿童节了，连篇累牍的校园性侵事件，为我们纪念这个节日平添了沉重的注脚。当然，历史而言...\n",
      "2          2  WTA世界排名第二的罗马尼亚名将哈勒普宣布，由于新冠肺炎疫情的蔓延，她决定不参加即将开战的美...\n",
      "3          3  教你用几毛钱做瓷砖清洁剂，清洁阿姨都不知道！1.准备一瓶500毫升的矿泉水，倒出一半；2.取...\n",
      "4          4  昨天，国家卫生计生委召开例行新闻发布会，围绕食品安全相关工作及社会热点答记者问。到2015年...\n",
      "...      ...                                                ...\n",
      "32995  32995  中新网长春4月6日电(记者崔颜锋)经吉林省政府“3.29”重大瓦斯事故调查组初步核实：吉林省...\n",
      "32996  32996  近日，由金牌编剧董润年导演并编剧，黄渤、王珞丹、谭卓、白客、黄璐、宋春丽、文淇领衔主演，丁溪...\n",
      "32997  32997  首先，夕阳中AnneHathaway婚纱的粉色不只是光线问题，设计稿中裙摆和头纱的下摆都是渐...\n",
      "32998  32998  6月9日，贵州省高考评卷工作专题组长培训会在贵州师范大学举行，对今年高考评卷工作提出了严格要...\n",
      "32999  32999  下面大宗网小编为您整理一下新股佰仁医疗(688198)的相关内容，希望对打新的小伙伴有所帮助...\n",
      "\n",
      "[33000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./unlabeled_data.csv\", engine=\"python\", encoding=\"utf_8_sig\")\n",
    "labels = ['财经','房产','家居','教育','科技','时尚','时政','游戏','娱乐','体育']\n",
    "id_list = []\n",
    "label_list = []\n",
    "content_list = []\n",
    "label_count = {}\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'科技'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bf6c5cbd3535>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlabel_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mid_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcontent_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '科技'"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    count = []\n",
    "    for j in range(len(labels)):\n",
    "        if labels[j] in df.iloc[i][1]:\n",
    "            count.append(j)\n",
    "    if len(count)==1:\n",
    "        label_count[labels[count[0]]] += 1\n",
    "        id_list.append(df.iloc[i][0])\n",
    "        content_list.append(df.iloc[i][1])\n",
    "        label_list.append(labels[count[0]])\n",
    "new_dict = {\"id\":id_list, \"class_label\":label_list, \"content\":content_list}\n",
    "new_df = pd.DataFrame(new_dict)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对两个数据样本融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"./train/newdata_from_unlabeled_data.csv\", index=False)\n",
    "df1 = pd.read_csv(\"./train/labeled_data.csv\", engine=\"python\", encoding=\"utf_8_sig\")\n",
    "df2 = pd.read_csv(\"./train/newdata_from_unlabeled_data.csv\")\n",
    "# 内容的列表\n",
    "content_list = []\n",
    "# 标签的列表\n",
    "labels_list = []\n",
    "for i in range(df1.shape[0]):\n",
    "    # 对数据进行第一步的清洗\n",
    "    s = df1.iloc[i][2].replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(chr(12288),\"\").replace(chr(8195),\"\")\n",
    "    content_list.append(s)\n",
    "    labels_list.append(labels.index(df1.iloc[i][1]))\n",
    "    \n",
    "for i in range(df2.shape[0]):\n",
    "    s = df2.iloc[i][2].replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(chr(12288),\"\").replace(chr(8195),\"\")\n",
    "    content_list.append([s])\n",
    "    labels_list.append(labels.index(df2.iloc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = { \"labels\":labels_list, \"contents\":content_list}\n",
    "new_df = pd.DataFrame(new_dict)\n",
    "shuffle(new_df)\n",
    "train = new_df.loc[0:10485]\n",
    "dev = new_df.loc[10485:13980]\n",
    "test = new_df.loc[13980:17475]\n",
    "train.to_csv(\"./train.txt\", index=False,header=False)\n",
    "dev.to_csv(\"./dev.txt\", index=False,header=False)\n",
    "test.to_csv(\"./test.txt\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
